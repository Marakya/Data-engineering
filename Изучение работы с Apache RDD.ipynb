{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uBcNQT4C1G-d"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем OpenJDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Закачиваем Spark\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop2.7.tgz -O spark.tgz\n",
        "# Распаковываем архив со Spark\n",
        "!tar xf spark.tgz\n",
        "# Устанавливаем пакет findspark для работы со Spark из Python\n",
        "!pip install -q findspark\n",
        "# Настраиваем переменные окружения для работы с Apache Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop2.7\"\n",
        "# Находим установку Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "# Подключаем необходимые модули для работы со Spark из Python\n",
        "from pyspark.sql import SparkSession\n",
        "# Создаем сессию Spark на локальном компьютере\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip -O /content/ml-100k.zip -q\n",
        "!unzip -qq /content/ml-100k.zip -d \"sample_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №1\n",
        "- вычислять и выводить на экран статистику по числу оценок для каждого фильма\n",
        "- вычислять и выводить на экран статистику по числу оценок для всех фильмов"
      ],
      "metadata": {
        "id": "Jx5OrzABM8Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "rdd = spark.sparkContext.textFile(\"/content/sample_data/ml-100k/u.data\")"
      ],
      "metadata": {
        "id": "ZiD1T792F_lp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairRdd = rdd.map(lambda x: (x.split('\\t')[1], x.split('\\t')[2]))\n",
        "aggPairRdd = pairRdd.groupByKey()"
      ],
      "metadata": {
        "id": "nNjylytrF_oG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printStat(inp):  \n",
        "  marks = []\n",
        "  ind, stat = inp  \n",
        "  for i in range(1, 6):\n",
        "    marks.append(stat.get(str(i), 0))\n",
        "  print(f'Marks for film {ind}: 1 -> {marks[0]}, 2 -> {marks[1]}, 3 -> {marks[2]}, 4 -> {marks[3]}, 5 -> {marks[4]}')"
      ],
      "metadata": {
        "id": "tcMn3yWDF_qg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Статистика для каждого фильма"
      ],
      "metadata": {
        "id": "Zr-z5MDnK6J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in aggPairRdd.mapValues(lambda x: dict(collections.Counter(x))).take(10):\n",
        "  printStat(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ExwvZmbF_tI",
        "outputId": "db4c6b1a-67e5-42b3-8267-f992933ba219"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marks for film 346: 1 -> 7, 2 -> 10, 3 -> 32, 4 -> 49, 5 -> 28\n",
            "Marks for film 474: 1 -> 0, 2 -> 6, 3 -> 34, 4 -> 59, 5 -> 95\n",
            "Marks for film 265: 1 -> 1, 2 -> 13, 3 -> 62, 4 -> 91, 5 -> 60\n",
            "Marks for film 465: 1 -> 4, 2 -> 8, 3 -> 26, 4 -> 30, 5 -> 17\n",
            "Marks for film 451: 1 -> 15, 2 -> 31, 3 -> 37, 4 -> 54, 5 -> 33\n",
            "Marks for film 86: 1 -> 4, 2 -> 10, 3 -> 23, 4 -> 67, 5 -> 46\n",
            "Marks for film 257: 1 -> 2, 2 -> 28, 3 -> 81, 4 -> 126, 5 -> 66\n",
            "Marks for film 222: 1 -> 7, 2 -> 30, 3 -> 108, 4 -> 155, 5 -> 65\n",
            "Marks for film 40: 1 -> 9, 2 -> 9, 3 -> 20, 4 -> 17, 5 -> 2\n",
            "Marks for film 29: 1 -> 15, 2 -> 34, 3 -> 45, 4 -> 14, 5 -> 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Статистика по всем фильмам"
      ],
      "metadata": {
        "id": "kM3sLfo-Mwgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairRdd_sum = rdd.map(lambda x: (x.split('\\t')[2], 1))\n",
        "aggPairRdd_sum = pairRdd_sum.groupByKey()  "
      ],
      "metadata": {
        "id": "1pH8bwaUIgpn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = dict()\n",
        "for i in aggPairRdd_sum.mapValues(lambda x: len(x)).take(10):\n",
        "  a,b = i\n",
        "  d[a] = b\n",
        "printStat(('All', d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_naYigw5Igr3",
        "outputId": "deb20050-a992-4570-d401-f8225c6a4a7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marks for film All: 1 -> 6110, 2 -> 11370, 3 -> 27145, 4 -> 34174, 5 -> 21201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание №2 Произведите подсчёт частоты встречаемости слов с использованием ApacheSpark RDD. "
      ],
      "metadata": {
        "id": "s82Xbny6M-5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Очистить текст от знаков препинания и пустых строк\n",
        "- Перевести в нижний регистр и разделить по пробелам\n",
        "- Подсчитать наиболее часто встречающиеся символы\n",
        "- Использовать RDD"
      ],
      "metadata": {
        "id": "LwhjdcrQNTpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.lib.ru/INOOLD/BALZAK/shagren.txt_Ascii.txt | iconv -f cp1251\n",
        "i = 0\n",
        "with open('/content/shagren.txt_Ascii.txt', encoding=\"cp1251\") as inF, open('/content/shagren.txt_utf8.txt', \"w\") as outF:\n",
        "  for line in inF:\n",
        "    outF.write(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlLTrabhM5t3",
        "outputId": "a195b7a5-e948-464b-a17a-c8c834ec41dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-22 09:57:25--  http://www.lib.ru/INOOLD/BALZAK/shagren.txt_Ascii.txt\n",
            "Resolving www.lib.ru (www.lib.ru)... 81.176.66.163\n",
            "Connecting to www.lib.ru (www.lib.ru)|81.176.66.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/plain]\n",
            "Saving to: ‘shagren.txt_Ascii.txt’\n",
            "\n",
            "shagren.txt_Ascii.t     [       <=>          ] 510.68K   338KB/s    in 1.5s    \n",
            "\n",
            "2022-11-22 09:57:29 (338 KB/s) - ‘shagren.txt_Ascii.txt’ saved [522937]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Очистим текст от знаков препинания и пустых строк\n",
        "def clean_text(x):\n",
        "  numbs = \"\"\"!\"#$%^&*()_-=,./;':\"<>?[]{}+@\"\"\"\n",
        "  # Перевод в нижний регистр и раздеим пробелами\n",
        "  lower = x.lower()\n",
        "  for i in numbs:\n",
        "    lower = lower.replace(i, '')\n",
        "  return lower"
      ],
      "metadata": {
        "id": "q2tRHys_NAiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчитываем наиболее встречающиеся символы\n",
        "rdd = spark.sparkContext.textFile(\"/content/shagren.txt_utf8.txt\")\n",
        "rdd = rdd.map(clean_text)\n",
        "rdd = rdd.flatMap(lambda s: s.split(' ')).filter(lambda x: x!='')\n",
        "rdd = rdd.map(lambda word: (word, 1)).reduceByKey(lambda x,y: (x+y)).map(lambda x: (x[1], x[0])).sortByKey(False).map(lambda x: (x[1], x[0]))\n",
        "rdd.take(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_P_8vuKNAlI",
        "outputId": "6ad5d4c1-8c5c-4abb-b045-f3c955651017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('и', 2204),\n",
              " ('в', 1977),\n",
              " ('я', 1252),\n",
              " ('не', 1247),\n",
              " ('на', 1094),\n",
              " ('он', 755),\n",
              " ('как', 717),\n",
              " ('с', 693),\n",
              " ('что', 653),\n",
              " ('его', 502)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}