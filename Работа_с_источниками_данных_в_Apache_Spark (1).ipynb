{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSTWoJSSEQ7i",
        "outputId": "69d4b13c-3cd0-4a2c-9a03-4c26c10c9331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sample_data/chinook.zip\n",
            "replace sample_data/chinook.db? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "# Устанавливаем OpenJDK\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Закачиваем Spark\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop2.7.tgz -O spark.tgz\n",
        "# Распаковываем архив со Spark\n",
        "!tar xf spark.tgz\n",
        "# Устанавливаем пакет findspark для работы со Spark из Python\n",
        "!pip install -q findspark\n",
        "# Настраиваем переменные окружения для работы с Apache Spark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop2.7\"\n",
        "# Настраиваем драйверы БД для работы Apache Spark с sqllite\n",
        "!wget https://repo1.maven.org/maven2/org/xerial/sqlite-jdbc/3.34.0/sqlite-jdbc-3.34.0.jar -q\n",
        "!wget https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.23/postgresql-42.2.23.jar -q\n",
        "!echo 'spark.jars /content/sqlite-jdbc-3.34.0.jar,/content/postgresql-42.2.23.jar' >> '/content/spark-3.2.0-bin-hadoop2.7/conf/spark-defaults.conf'\n",
        "# Находим установку Spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "# Подключаем необходимые модули для работы со Spark из Python\n",
        "from pyspark.sql import SparkSession\n",
        "# Создаем сессию Spark на локальном компьютере\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "!wget https://www.sqlitetutorial.net/wp-content/uploads/2018/03/chinook.zip -O 'sample_data/chinook.zip' -q\n",
        "!unzip \"sample_data/chinook.zip\" -d \"sample_data/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update &>log0 && apt install postgresql postgresql-contrib &>log1\n",
        "!service postgresql start\n",
        "!sudo -u postgres psql -c 'CREATE DATABASE mydatabase'\n",
        "!sudo -u postgres psql -c \"CREATE USER me WITH ENCRYPTED PASSWORD 'mypass'\"\n",
        "!sudo -u postgres psql -c 'CREATE SCHEMA AUTHORIZATION \"me\";'\n",
        "!sudo -u postgres psql -c 'GRANT ALL PRIVILEGES ON DATABASE mydatabase TO me'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvotmnCpFbcu",
        "outputId": "a5c05868-f04b-41f2-a90d-6826dbf73e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Starting PostgreSQL 10 database server\n",
            "   ...done.\n",
            "CREATE DATABASE\n",
            "CREATE ROLE\n",
            "CREATE SCHEMA\n",
            "GRANT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В mydatabase должны создасться 11 таблиц\n",
        "\n",
        "Вывод проверочного скрипта"
      ],
      "metadata": {
        "id": "k1sPoNIlqiQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "sqlite = create_engine(\"sqlite:///sample_data/chinook.db\") \n",
        "postgresql = create_engine(\"postgresql://me:mypass@localhost/mydatabase\") \n",
        "jdbcDriverLite = 'org.sqlite.JDBC'\n",
        "jdbcUrlLite = 'jdbc:sqlite:sample_data/chinook.db'\n",
        "jdbcUrlPost = 'jdbc:postgresql://localhost/mydatabase?user=me&password=mypass'\n",
        "jdbcDriverPost= 'org.postgresql.Driver'"
      ],
      "metadata": {
        "id": "K5vLyJvjFbex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with sqlite.connect() as lite, lite.begin(), postgresql.connect() as post, post.begin():\n",
        "  cursor = lite.execute('''SELECT name, sql FROM sqlite_master WHERE type ='table' AND name NOT LIKE 'sqlite_%';''')\n",
        "  for row in cursor:\n",
        "    tab = row['name'] \n",
        "    field = [] \n",
        "    col = []\n",
        "    innerCursor = lite.execute(f'''SELECT name, type FROM pragma_table_info('{tab}') c''')\n",
        "    for innerRow in innerCursor:\n",
        "      field.append(innerRow['name']+ ' ' + str(innerRow['type']).replace('NVARCHAR', 'VARCHAR').replace('DATETIME','VARCHAR(100)'))    \n",
        "      col.append('cast(' + innerRow['name'] + ' as text)' if innerRow['type'] == 'DATETIME' else innerRow['name'])\n",
        "    ddl = f\"CREATE TABLE IF NOT EXISTS {tab} (\\n\" + \",\\n\".join(field) + \");\"\n",
        "    postgresql.execute(ddl)\n",
        "    print('(select ' + \", \".join(col) + f' from {tab}) as {tab}')\n",
        "    df = spark.read.format('jdbc').options(driver=jdbcDriverLite, dbtable='(select ' + \", \".join(col) + f' from {tab}) as {tab}', url=jdbcUrlLite).load()\n",
        "    df.write.format(\"jdbc\").option(\"url\", jdbcUrlPost).option(\"driver\",jdbcDriverPost).option(\"dbtable\", tab).mode(\"overwrite\").save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUI-diBXFbgz",
        "outputId": "680684e4-c0b4-4e6c-bd8a-6a4e092ca37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(select AlbumId, Title, ArtistId from albums) as albums\n",
            "(select ArtistId, Name from artists) as artists\n",
            "(select CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId from customers) as customers\n",
            "(select EmployeeId, LastName, FirstName, Title, ReportsTo, cast(BirthDate as text), cast(HireDate as text), Address, City, State, Country, PostalCode, Phone, Fax, Email from employees) as employees\n",
            "(select GenreId, Name from genres) as genres\n",
            "(select InvoiceId, CustomerId, cast(InvoiceDate as text), BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total from invoices) as invoices\n",
            "(select InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity from invoice_items) as invoice_items\n",
            "(select MediaTypeId, Name from media_types) as media_types\n",
            "(select PlaylistId, Name from playlists) as playlists\n",
            "(select PlaylistId, TrackId from playlist_track) as playlist_track\n",
            "(select TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice from tracks) as tracks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверочный скрипт"
      ],
      "metadata": {
        "id": "S2L0C6ecHqvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "postgresql = create_engine(\"postgresql://me:mypass@localhost/mydatabase\")\n",
        "\n",
        "with postgresql.connect() as post, post.begin():\n",
        "  cursor = post.execute('''SELECT * FROM pg_catalog.pg_tables where schemaname = 'public';''')\n",
        "  for row in cursor:\n",
        "    print(row['schemaname'] + '.' + row['tablename'])\n",
        "    innerCursor = post.execute(f'''SELECT count(*) cnt FROM {row['schemaname']}.{row['tablename']};''')\n",
        "    for innerRow in innerCursor:\n",
        "      print(f'''Rows count: {innerRow['cnt']}''')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH9dnhRgFuNX",
        "outputId": "b52fb854-723a-44f7-de52-edef395bfc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "public.invoices\n",
            "Rows count: 412\n",
            "public.tracks\n",
            "Rows count: 3503\n",
            "public.albums\n",
            "Rows count: 347\n",
            "public.invoice_items\n",
            "Rows count: 2240\n",
            "public.artists\n",
            "Rows count: 275\n",
            "public.media_types\n",
            "Rows count: 5\n",
            "public.customers\n",
            "Rows count: 59\n",
            "public.playlists\n",
            "Rows count: 18\n",
            "public.employees\n",
            "Rows count: 8\n",
            "public.genres\n",
            "Rows count: 25\n",
            "public.playlist_track\n",
            "Rows count: 8715\n"
          ]
        }
      ]
    }
  ]
}